import gradio as gr
import openai, config, subprocess
openai.api_key = config.OPENAI_API_KEY

messages = [{"role": "system", "content": 'You are a programming assistant. \
You are an expert in coding projects written in the Swift coding language. \
You are an expert in using Object Oriented design principles. \
You are an expert at using SOLID coding principles. \
Respond to all input in 5000 words or less. \
Print the number of words in this message variable to stdout like: Number of words used: {Some number of words} ' }]

def transcribe( fileNameArg, textFromTextbox ):
    global messages
    
    audio = None
    
    print( "textFromTextbox: " + textFromTextbox )
    if (audio is None):
        # get the text from the textbox input
        messages.append({ "role": "user", "content": textFromTextbox })
    else:
        print("Audio received")
        audio_file = open(audio, "rb")
        transcript = openai.Audio.transcribe("whisper-1", audio_file)
        messages.append({ "role": "user", "content": transcript["text"] })

    # get the response from the gpt-3 model and limit the response to 25 words
    # response = openai.ChatCompletion.create( model="gpt-3.5-turbo", messages=messages, max_tokens=1000 )
    response = openai.ChatCompletion.create( model="gpt-4", messages=messages, max_tokens=1000 )
    
    

    system_message = response["choices"][0]["message"]
    
    messages.append(system_message)
    
    
    with open( fileNameArg, "w") as file:
        file.write( system_message[ 'content' ])

    # subprocess.call(["say", system_message['content']])
    # print the system_message['content'] to the console
    print( system_message['content'] )

    chat_transcript = ""
    for message in messages:
        if message['role'] != 'system':
            chat_transcript += message['role'] + ": " + message['content'] + "\n\n"

    return chat_transcript

# add a gr.Interface with a microphone and text input and a text output
# This is the command used for making an interface with the gradio library: 
# ui = gr.Interface(fn=transcribe, inputs=gr.Audio(source="microphone", type="filepath"), outputs="text").launch() 
# It only shows a record icon and a microphone input. 
# I need a microphone source AND a textbox source. will you modify this python code
# so that it will also show a textbox input? 
# ui =
# ui = gr.Interface(fn=transcribe, inputs=[gr.Audio(source="microphone", type="filepath"), gr.inputs.Textbox()], outputs="text")
# ui = gr.Interface(fn=transcribe, inputs=[gr.inputs.Textbox()], outputs="text")
# ui = gr.Interface(fn=transcribe, inputs=gr.Audio(source="microphone", type="filepath"), outputs="text").launch()
# I also need another text input for the file name.  
# I need to be able to save the code that is generated by the gpt-3 model.
# give meaningful names to each of the inputs.  I need to be able to reference them in the code.
ui = gr.Interface(fn=transcribe, inputs=[ gr.inputs.Textbox(label="Enter the file name"),  \
                                          gr.inputs.Textbox(label="Enter the instructions")], outputs="text" ) 



ui.launch()